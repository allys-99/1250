
# How Big Data Is Helping Drivers Stay Safer on the Road

https://insidebigdata.com/2018/12/27/big-data-helping-drivers-stay-safer-road/

This time of year is graduation.  Every year at this time there are awful car accidents
with involving young people.  The sooner humans are not driving the safer the roads will be.
Big Data can show people where the problem areas are.  With statistics like 80% of crashes are
due to human error, people will pay attention.

https://www.pewtrusts.org/en/research-and-analysis/blogs/stateline/2017/02/09/troopers-use-big-data-to-predict-crash-sites
The state of Tennessee, used big data to actually map accidents sites for the public.  This
is very helpful to know that the next bend you are coming around previously had 3 accidents a year.

https://insidebigdata.com/2018/12/27/big-data-helping-drivers-stay-safer-road/
The people that are on the road every day to earn their living.  Businesses can benifit
from the data collected.



***
# Data lake security

Storing information is one thing and the important thing is to secure the data in a datalake.
Apprently there are 4 areas to secure in a datalake: Platform Access & privileges,
Network Isolation, Data Protection and Document Level Security.  It's a brief insight into
where security needs to be in place.
Breaking down the structure of security makes it easier to implement and understand.

https://www.searchtechnologies.com/blog/data-lake-security


***
# A Data Lake Architecture with Hadoop and Open Source Search Engines

The examples used in this article helps to understand what are some of
the challenges are when using a data lake.  With time, there will be more
applications or search engines that will sift through all that data
in a reasonable amount of time and then make it easier for data warehouses
to do their work.


https://www.searchtechnologies.com/blog/search-data-lake-with-big-data


***

# Dark Data

I learned that there is another kind of Data besides Big Data, Dark Data.
We are focused on getting monetary value out of data so we take what we
need and leave the rest.  There is a place and a name for the data that is
not used or anlysed and that is Dark Data.  Apparently, 90% of collected data
is Dark Data.  The data that is not used could have hidden values as well
as legal implications.

In the case of data collected from a long time ago (maybe that's 10 years),
when technology did not exist to process the data efficiently, that old data
could find itself in a lake and be used.  For example climate change would be
a good candidate where data has been collected since 1860.  It could help to
find weather patterns over long periods of time.

https://www.kdnuggets.com/2015/11/importance-dark-data-big-data-world.html

https://www.kdnuggets.com/2015/01/shining-light-on-dark-data.html



***
# What is a data lake? Flexible big data management explained

https://www.infoworld.com/article/3305843/what-is-a-data-lake-flexible-big-data-management-explained.html
 

This was a good explanation of Data lake vs data warehouse.  It is good to read the definition
as seen through many eyes.  I didn't realize that data warehouses require special hardware also.
I thought it was just software.  Of course modern computers are faster but i assume it would 
run just slower. The article nicely explains in which case you would not need a data lake.  Also,
it seems that there are people out there that believe data lake is a bad idea and call it the 
lazy way out.  I think it's like when you have a house, a lot of stuff goes in and it only gets
cleaned out when we move out.
